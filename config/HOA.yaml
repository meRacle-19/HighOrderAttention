#data
#data format:ffm
data:
     # infer_file  :  data/test.ffm
#     train_file : data/sample_1w/train.ffm
#     eval_file  : data/sample_1w/eval.ffm
#     test_file  : data/sample_1w/test.ffm
#     FEATURE_COUNT : 13553
#     train_file : data/sample_10w/train.ffm
#     eval_file  : data/sample_10w/eval.ffm
#     test_file  : data/sample_10w/test.ffm
#     FEATURE_COUNT : 66384
     train_file : data/sample_1000w/train.ffm
     eval_file  : data/sample_1000w/eval.ffm
     test_file  : data/sample_1000w/test.ffm
     FEATURE_COUNT : 1806715
     FIELD_COUNT :  39
     data_format : ffm

#model
#model_type:HOA DACN
model:
    method : classification
    model_type : HOA
    embedding_dim : 10
    orders : 3
    dropout : [0.0]
    cross_layer_heads : [2, 2, 2]
    cross_layer_dims : [32, 16, 8]                # working if do_projection=True

    # combination part
    layer_sizes : [128, 128, 1]
    layer_activations : [relu, relu, identity]

    # working if reduce=mlp_pooling
    reduce_layer_sizes : [256, 128, 256, 128, 256, 128, 256, 128]
    reduce_layer_activations : [elu, identity, elu, identity, elu, identity, elu, identity]

    # working if dnn part valid
    dnn_layer_sizes : [256, 256, 256, 1]
    dnn_layer_activations : [relu, relu, relu, identity]
#    load_model_name : ./checkpoint/epoch_1


#train
#init_method: normal,tnormal,uniform,he_normal,he_uniform,xavier_normal,xavier_uniform
train:
    init_method: tnormal
    init_value : 0.1
    embed_l2 : 0.0005
    embed_l1 : 0.00
    layer_l2 : 0.0005
    layer_l1 : 0.00
    learning_rate : 0.0005
    loss : log_loss
    optimizer : adam
    epochs : 20
    batch_size : 512

#show info
#metric :'auc','logloss', 'group_auc'
info:
    show_step : 20
    save_epoch : 10
    metrics : ['auc','logloss']

